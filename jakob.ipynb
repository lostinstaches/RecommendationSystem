{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "from plots import plot_train_test_data\n",
    "from helpers import split_data\n",
    "from helpers import init_MF\n",
    "from plots import plot_raw_data\n",
    "from helpers import calculate_mse\n",
    "\n",
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "path_dataset = \"./data/de_data_train.csv\"\n",
    "ratings = load_data(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nonzero elements in origial data:1176952\n",
      "Total number of nonzero elements in train data:1059177\n",
      "Total number of nonzero elements in test data:117775\n"
     ]
    }
   ],
   "source": [
    "valid_ratings, train, test, x, x = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=0, p_test=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import build_index_groups\n",
    "_, nz_item_userindices, nz_user_itemindices = build_index_groups(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_per_user = []\n",
    "for item, users in nz_item_userindices:\n",
    "    items_per_user.append(len(users))\n",
    "# the histogram of the data\n",
    "n, bins, patches = plt.hist(items_per_user, 50, density=True, facecolor='g', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_per_user = []\n",
    "for user, items in nz_user_itemindices:\n",
    "    items_per_user.append(len(items))\n",
    "# the histogram of the data\n",
    "n, bins, patches = plt.hist(items_per_user, 50, density=True, facecolor='g', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.]]\n",
      "RMSE global: 1.1292694921026554\n"
     ]
    }
   ],
   "source": [
    "def baseline_global_mean(train, test):\n",
    "    \"\"\"baseline method: use the global mean.\"\"\"\n",
    "    global_mean = train[train.nonzero()].mean()\n",
    "    nnz_test = test[test.nonzero()].todense() \n",
    "    mse = calculate_mse(nnz_test, global_mean)\n",
    "    rmse = np.sqrt(mse / nnz_test.shape[1])\n",
    "    return np.squeeze(rmse).item()\n",
    "def baseline_global_median(train, test):\n",
    "    \"\"\"baseline method: use the global mean.\"\"\"\n",
    "    global_mean = np.squeeze(np.median(train[train.nonzero()].todense(), axis=1))\n",
    "    nnz_test = test[test.nonzero()].todense() \n",
    "    mse = calculate_mse(nnz_test, global_mean)\n",
    "    rmse = np.sqrt(mse / nnz_test.shape[1])\n",
    "    return np.squeeze(rmse).item()\n",
    "print(\"RMSE global: {}\".format(baseline_global_mean(train, test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE user-mean: 1.0319099240955811\n"
     ]
    }
   ],
   "source": [
    "def baseline_user_mean(train, test):\n",
    "    \"\"\"baseline method: use the user means as the prediction.\"\"\"\n",
    "    mse = 0\n",
    "    _, num_users = train.shape\n",
    "    for user in range(num_users):\n",
    "        user_ratings_train = train[:, user]\n",
    "        nnz_train = user_ratings_train[user_ratings_train.nonzero()]\n",
    "        if nnz_train.shape[0] == 0:\n",
    "            continue\n",
    "        user_mean = nnz_train.mean()            \n",
    "        user_ratings_test = test[:, user]\n",
    "        nnz_test = user_ratings_test[user_ratings_test.nonzero()].todense()\n",
    "        mse += calculate_mse(nnz_test, user_mean)\n",
    "    return np.sqrt(1.0 * mse / test.nnz).item()\n",
    "print(\"RMSE user-mean: {}\".format(baseline_user_mean(train, test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE item-mean: 1.0959075588942098\n"
     ]
    }
   ],
   "source": [
    "def baseline_item_mean(train, test):\n",
    "    \"\"\"baseline method: use item means as the prediction.\"\"\"\n",
    "    return baseline_user_mean(train.T, test.T)\n",
    "print(\"RMSE item-mean: {}\".format(baseline_item_mean(train, test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_row = nnz_elements.shape[1]\n",
    "interval = int(num_row / k_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.118953132828715\n",
      "1.1202690744172918\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6399e88c7366>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mitem_cross_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-6399e88c7366>\u001b[0m in \u001b[0;36mitem_cross_val\u001b[0;34m(k_fold)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mtrain_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnz_elements\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_item_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-4abf7a5ad998>\u001b[0m in \u001b[0;36mbaseline_item_mean\u001b[0;34m(train, test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbaseline_item_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"baseline method: use item means as the prediction.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbaseline_user_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(\"RMSE item-mean: {}\".format(baseline_item_mean(train, test)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'T'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'H'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/sparse/lil.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(self, axes, copy)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0mtranspose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36mtolil\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mresultant\u001b[0m \u001b[0mlil_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \"\"\"\n\u001b[0;32m--> 913\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtodia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36mtolil\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtolil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlil_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mlil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlil_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/sparse/lil.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unrecognized lil_matrix constructor usage'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# USER / ITEM / GLOBAL CROSSVAL\n",
    "\n",
    "def build_indexes(data, k_fold=5):\n",
    "    num_row = data.shape[1]\n",
    "    interval = int(num_row / k_fold)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return k_indices\n",
    "\n",
    "def global_cross_val(k_fold=5):\n",
    "    nnz_elements = ratings[ratings.nonzero()]\n",
    "    k_indices = build_indexes(nnz_elements, k_fold=5)\n",
    "    res = []\n",
    "    for k in range(k_fold):\n",
    "        test = nnz_elements[:, k_indices[k]]\n",
    "        train_idx = []\n",
    "        for i in range(k_fold):\n",
    "            if i == k:\n",
    "                continue\n",
    "                \n",
    "            if len(train_idx) ==  0:\n",
    "                train_idx = k_indices[i]\n",
    "            else:\n",
    "                train_idx = np.concatenate([train_idx, k_indices[i]])\n",
    "        train = nnz_elements[:, train_idx]\n",
    "        mean = baseline_global_mean(train,test)\n",
    "        res.append(mean)\n",
    "    print(np.sum(res)/k_fold)\n",
    "    \n",
    "    \n",
    "def item_cross_val(k_fold=5):\n",
    "    nnz_elements = ratings[ratings.nonzero()]\n",
    "    k_indices = build_indexes(nnz_elements, k_fold=5)\n",
    "    res = []\n",
    "    for k in range(k_fold):\n",
    "        test = nnz_elements[:, k_indices[k]]\n",
    "        train_idx = []\n",
    "        for i in range(k_fold):\n",
    "            if i == k:\n",
    "                continue\n",
    "                \n",
    "            if len(train_idx) ==  0:\n",
    "                train_idx = k_indices[i]\n",
    "            else:\n",
    "                train_idx = np.concatenate([train_idx, k_indices[i]])\n",
    "        train = nnz_elements[:, train_idx]\n",
    "        mean = baseline_item_mean(train,test)\n",
    "        print(mean)\n",
    "        res.append(mean)\n",
    "    print(np.sum(res)/k_fold)\n",
    "    \n",
    "def user_cross_val(k_fold=5):\n",
    "    nnz_elements = ratings[ratings.nonzero()]\n",
    "    k_indices = build_indexes(nnz_elements, k_fold=5)\n",
    "    res = []\n",
    "    for k in range(k_fold):\n",
    "        test = nnz_elements[:, k_indices[k]]\n",
    "        train_idx = []\n",
    "        for i in range(k_fold):\n",
    "            if i == k:\n",
    "                continue\n",
    "\n",
    "            if len(train_idx) ==  0:\n",
    "                train_idx = k_indices[i]\n",
    "            else:\n",
    "                train_idx = np.concatenate([train_idx, k_indices[i]])\n",
    "        train = nnz_elements[:, train_idx]\n",
    "        mean = baseline_user_mean(train,test)\n",
    "        print(mean)\n",
    "        res.append(mean)\n",
    "    print(np.sum(res)/k_fold)\n",
    "    \n",
    "    \n",
    "    \n",
    "item_cross_val()\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline estimate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SGD...\n",
      "iter: 0, RMSE on training set: 0.9994629076738408.\n",
      "iter: 1, RMSE on training set: 0.9956075486578966.\n",
      "iter: 2, RMSE on training set: 0.99370587331951.\n",
      "iter: 3, RMSE on training set: 0.9930551822462327.\n",
      "iter: 4, RMSE on training set: 0.9924684505310238.\n",
      "iter: 5, RMSE on training set: 0.9920580299985728.\n",
      "iter: 6, RMSE on training set: 0.9915115565597591.\n",
      "iter: 7, RMSE on training set: 0.9913468214722916.\n",
      "iter: 8, RMSE on training set: 0.9911768392951089.\n",
      "iter: 9, RMSE on training set: 0.9910120783857594.\n",
      "RMSE on test data: 1.001507976095007.\n"
     ]
    }
   ],
   "source": [
    "def compute_error_baseline_estimate(data, \n",
    "                                    nz, \n",
    "                                    user_bias, \n",
    "                                    item_bias, \n",
    "                                    global_bias,\n",
    "                                    lambda_user_bias,\n",
    "                                    lambda_item_bias):\n",
    "    mse = 0\n",
    "    for item, user in nz:\n",
    "        prediction = global_bias + item_bias[item] + user_bias[user]\n",
    "        mse += (data[item, user] - prediction) ** 2\n",
    "    reg = lambda_user_bias * user_bias.T.dot(user_bias) + lambda_item_bias * item_bias.T.dot(item_bias)\n",
    "    mse += reg\n",
    "    return np.sqrt(mse / len(nz))\n",
    "\n",
    "\n",
    "# See 2.1 http://www.cs.rochester.edu/twiki/pub/Main/HarpSeminar/Factorization_Meets_the_Neighborhood-_a_Multifaceted_Collaborative_Filtering_Model.pdf\n",
    "def baseline_estimate(train,\n",
    "                      test,\n",
    "                      gamma=0.02, \n",
    "                      num_features=20,\n",
    "                      lambda_user_bias=0.1,\n",
    "                      lambda_item_bias=0.1,\n",
    "                      num_epochs=10):\n",
    "    \n",
    "    global_bias = train[train.nonzero()].mean()\n",
    "    \n",
    "    # He init\n",
    "    user_bias = np.random.normal(scale=np.sqrt(2/num_features), size=train.shape[1])\n",
    "    item_bias = np.random.normal(scale=np.sqrt(2/num_features), size=train.shape[0])\n",
    "    \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "\n",
    "    print(\"Starting SGD...\")\n",
    "    for it in range(num_epochs):\n",
    "        np.random.shuffle(nz_train)\n",
    "        gamma /= 1.2\n",
    "        for d, n in nz_train:\n",
    "            prediction = global_bias + user_bias[n] + item_bias[d]\n",
    "            error = train[d, n] - prediction\n",
    "            # Update variables\n",
    "            user_bias[n] +=  gamma * (error - lambda_user_bias * user_bias[n])\n",
    "            item_bias[d] +=  gamma * (error - lambda_item_bias * item_bias[d])\n",
    "        rmse = compute_error_baseline_estimate(train, \n",
    "                                               nz_train, \n",
    "                                               user_bias, \n",
    "                                               item_bias, \n",
    "                                               global_bias,\n",
    "                                               lambda_user_bias,\n",
    "                                               lambda_item_bias)\n",
    "        print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse))\n",
    "        \n",
    "    rmse = compute_error_baseline_estimate(test, \n",
    "                                           nz_test, \n",
    "                                           user_bias, \n",
    "                                           item_bias,\n",
    "                                           global_bias,\n",
    "                                           lambda_user_bias,\n",
    "                                           lambda_item_bias)\n",
    "    print(\"RMSE on test data: {}.\".format(rmse))\n",
    "    \n",
    "    return user_bias, item_bias, global_bias \n",
    "\n",
    "user_bias, item_bias, global_bias = baseline_estimate(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import create_submission_baseline_estimate\n",
    "create_submission_baseline_estimate(user_bias, item_bias, global_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import build_index_groups\n",
    "\n",
    "nz_train, nz_item_userindices, nz_user_itemindices = build_index_groups(train)\n",
    "\n",
    "num_items, num_users = train.shape\n",
    "for user, items in nz_user_itemindices:\n",
    "    user_means[user] = train[items, user].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes ~10 min to compute!\n",
    "def construct_similarity_matrix(data, nz_user_userindices):\n",
    "    num_items, num_users = data.shape\n",
    "    print(\"Constructing sim matrix\")\n",
    "    similarity_matrix = np.zeros((num_users, num_users))\n",
    "    for i, items_i in nz_user_itemindices:\n",
    "        print(i)\n",
    "        for j, items_j in nz_user_itemindices:\n",
    "            if i == j:\n",
    "                continue\n",
    "                            \n",
    "            item_intersection = np.intersect1d(items_i, items_j)\n",
    "            \n",
    "            if len(item_intersection) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Calculate pearson coefficient, could might as well have used np.corrcoef\n",
    "            # but calculatig it yourself is so much more fun!\n",
    "            \n",
    "            r_i = data[item_intersection, i].todense()\n",
    "            r_i = r_i -  r_i.mean()\n",
    "            r_j = data[item_intersection, j].todense()\n",
    "            r_j = r_j -  r_j.mean()\n",
    "     \n",
    "            numerator = r_i.T @ r_j\n",
    "\n",
    "            denominator = np.sqrt(r_i.T.dot(r_i)) * np.sqrt(r_j.T.dot(r_j))\n",
    "            similarity_matrix[i, j] = numerator / denominator if denominator > 0 else 0       \n",
    "            \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_s_matrix(train, nz_train, user_means):\n",
    "    s_matrix = sp.lil_matrix(train.shape)\n",
    "    #nz_row, nz_col = train.nonzero()\n",
    "    #nz_train = list(zip(nz_row, nz_col))\n",
    "    print(\"Constructing S matrix...\")\n",
    "    for d, n in nz_train:\n",
    "        s_matrix[d, n] = train[d, n] - user_means[n]\n",
    "    return s_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_knn(similarity_matrix, s_matrix, test, k, nz_item_userindices, similarity_treshold=0.1):\n",
    "    mse = 0\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "    iters = 0\n",
    "    print(\"Starting evaluation..\")\n",
    "    for d, n in nz_test:\n",
    "        iters += 1\n",
    "        if iters % 10000 == 0:\n",
    "            print(iters)\n",
    "            \n",
    "        # Get index of k most similar users\n",
    "        # Set all similarityis not in d_users to zero -> argsort -> take top k.\n",
    "        _, d_users = nz_item_userindices[d]\n",
    "        d_users_similarity = similarity_matrix[n, :].copy()\n",
    "        kn_index = np.zeros(similarity_matrix.shape[1])\n",
    "        kn_index[d_users] = similarity_matrix[n, d_users]\n",
    "        kn_index = kn_index.argsort()[-k:][::-1]\n",
    "\n",
    "        kn_similarity = kn_similarity[n, kn_index] \n",
    "        \n",
    "        kn_mean_centered_rating = s_matrix[d, kn_index].todense()\n",
    "        kn_mean_centered_rating = np.squeeze(np.asarray(kn_mean_centered_rating))\n",
    "        \n",
    "        # Remove users with low similarity as described, heuristic desribed in 2.3.1\n",
    "        kn_mean_centered_rating = kn_mean_centered_rating[kn_similarity > similarity_treshold]\n",
    "        kn_similarity = kn_similarity[kn_similarity > similarity_treshold]\n",
    "\n",
    "        # Compute prediction\n",
    "        numerator = kn_mean_centered_rating.dot(kn_similarity)\n",
    "        denominator = np.sum(np.abs(similarity_matrix[n, kn_index]))\n",
    "        \n",
    "        prediction = numerator / denominator\n",
    "    \n",
    "        user_mean = user_means[n]\n",
    "        prediction = user_mean + prediction\n",
    "        \n",
    "        # Compute error\n",
    "        mse += (test[d, n] - prediction) ** 2\n",
    "        \n",
    "    return np.sqrt(mse / len(nz_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = construct_similarity_matrix(train, nz_user_itemindices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-specific KNN\n",
    "def KNN(similarity_matrix, train, test, k, nz_train, nz_item_userindices, nz_user_itemindices, user_means):\n",
    "    #nz_train, nz_item_userindices, nz_user_itemindices = build_index_groups(train)\n",
    "    #similarity_matrix = construct_similarity_matrix(train, nz_user_itemindices)\n",
    "    s_matrix = construct_s_matrix(train, nz_train, user_means)\n",
    "    print(evaluate_knn(similarity_matrix, s_matrix, test, k, nz_item_userindices))\n",
    "    \n",
    "KNN(similarity_matrix,  train, test, 40, nz_train, nz_item_userindices, nz_user_itemindices, user_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "model = NearestNeighbors(n_neighbors=25, metric='correlation')\n",
    "model.fit(train.todense())\n",
    "distances, indices = model.kneighbors(test.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71805531 0.72333828 0.72889909 0.73265069 0.74629688 0.76158883\n",
      " 0.7670455  0.7752808  0.77637654 0.78435691 0.79026452 0.79066985\n",
      " 0.79232536 0.79292786 0.79354054 0.79468498 0.80946411 0.81175635\n",
      " 0.81250677 0.81265502 0.81674545 0.81690947 0.81691794 0.81733007\n",
      " 0.81753813]\n",
      "[6494 4381 4031 2692 5496 4681 4714 1793 6651  833 9760 6695 9594 7485\n",
      " 1324 3891 9864 6192 6124 2376 2843 5027 7361  510 9852]\n"
     ]
    }
   ],
   "source": [
    "print(distances[0])\n",
    "print(indices[0])\n",
    "#print(distances.shape)\n",
    "#print(indices.shape)\n",
    "\n",
    "#for d, n in nz_test[:20000]:\n",
    "#    k_near = distances[n]\n",
    "#    \n",
    "#    numerator = np.sum(sim * s)\n",
    "#    denominator = np.sum(np.abs(similarity_matrix[n, k_similar_index]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A NEIGHBORHOOD MODEL\n",
    "http://www.cs.rochester.edu/twiki/pub/Main/HarpSeminar/Factorization_Meets_the_Neighborhood-_a_Multifaceted_Collaborative_Filtering_Model.pdf\n",
    "\n",
    "probably too computationally heavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn the matrix factorization using SGD...\n",
      "1\n",
      "10001\n",
      "20001\n",
      "30001\n",
      "40001\n",
      "50001\n",
      "60001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-395-08130c71764a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m                                                            \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.013\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                                            \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                                                            num_features=20)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-395-08130c71764a>\u001b[0m in \u001b[0;36mneighborhood_model\u001b[0;34m(train, test, num_features, gamma, lambda_user_bias, lambda_item_bias, lambda_w, lambda_c, num_epochs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_mean\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitem_bias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0muser_bias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mt_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlSqrt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt_items\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlambda_w\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlSqrt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0merror\u001b[0m  \u001b[0;34m-\u001b[0m \u001b[0mlambda_c\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/sparse/lil.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_row_ranges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/sparse/lil.py\u001b[0m in \u001b[0;36m_get_row_ranges\u001b[0;34m(self, rows, col_slice)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mcol_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj_stride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mnj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlil_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         _csparsetools.lil_get_row_ranges(self.shape[0], self.shape[1],\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/sparse/lil.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def compute_error_neighborhood(data, user_features, item_features, nz):\n",
    "    mse = 0   \n",
    "    for row, col in nz:\n",
    "        p = user_features[:, col]\n",
    "        q = item_features[:, row]\n",
    "        prediction = p.T.dot(q)\n",
    "        mse += (data[row, col] - prediction)**2\n",
    "    return np.sqrt(1.0 * mse / len(nz))\n",
    "\n",
    "def neighborhood_model(train, \n",
    "                             test, \n",
    "                             num_features=20, \n",
    "                             gamma=0.05, \n",
    "                             lambda_user_bias=0.1, \n",
    "                             lambda_item_bias=0.1,\n",
    "                             lambda_w=0.1,\n",
    "                             lambda_c=0.1,\n",
    "                             num_epochs=10):     \n",
    "    \"\"\"matrix factorization by SGD.\"\"\"\n",
    "\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    \n",
    "    global_mean = train[train.nonzero()].mean()\n",
    "    user_bias = np.random.normal(scale=np.sqrt(2/num_features), size=train.shape[1])\n",
    "    item_bias = np.random.normal(scale=np.sqrt(2/num_features), size=train.shape[0])\n",
    "    w = np.random.normal(scale=np.sqrt(2/num_features), size=train.shape)\n",
    "    c = np.random.normal(scale=np.sqrt(2/num_features), size=train.shape)\n",
    "    \n",
    "    # find the non-zero ratings indices \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "    \n",
    "    nz_train, nz_item_userindices, nz_user_itemindices = build_index_groups(train)\n",
    "\n",
    "\n",
    "    print(\"learn the matrix factorization using SGD...\")\n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # decrease step size\n",
    "        gamma /= 1.2\n",
    "\n",
    "        iters = 0\n",
    "        for d, n in nz_train:\n",
    "            iters += 1\n",
    "            if iters % 10000 == 1:\n",
    "                print(iters)\n",
    "            \n",
    "            user, items = nz_user_itemindices[n]\n",
    "            items = items[: 500]\n",
    "            \"\"\"\"\n",
    "            ws = 0\n",
    "            cs = 0\n",
    "            for item in items:\n",
    "                if item == d:\n",
    "                    continue\n",
    "                b = global_mean + item_bias[item] + user_bias[n]\n",
    "                ws += (train[item, n] - b) * w[item, n]\n",
    "                cs += c[item, n]\n",
    "            \"\"\"\n",
    "                \n",
    "            b = global_mean + item_bias[items] + user_bias[n]\n",
    "\n",
    "            ws = (np.squeeze(np.asarray(train[items, n].todense())) - b) @ w[items, n]\n",
    "            cs = np.sum(c[items, n])\n",
    "            lSqrt = np.sqrt(len(items))\n",
    "\n",
    "            base_prediction = global_mean + item_bias[d] + user_bias[n]\n",
    "            prediction = base_prediction + ws/lSqrt + cs/lSqrt\n",
    "            error = train[d, n] - prediction\n",
    "\n",
    "                        \n",
    "            # Update variables\n",
    "            user_bias[n] +=  gamma * (error - lambda_user_bias * user_bias[n])\n",
    "            item_bias[d] +=  gamma * (error - lambda_item_bias * item_bias[d])\n",
    "            \n",
    "            bs = global_mean + item_bias[items] + user_bias[n]         \n",
    "            t_items = np.squeeze(np.asarray(train[items,n].todense()))\n",
    "            w[items, n] += gamma * ((1/lSqrt) * error * (t_items - bs) - lambda_w * w[items, n])\n",
    "            c[items, n] += gamma * ((1/lSqrt) * error  - lambda_c * c[items, n])\n",
    "            \n",
    "\n",
    "     \n",
    "        rmse = compute_error_neighborhood(train, user_features, item_features, nz_train)\n",
    "        print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse)) \n",
    "        rmse = compute_error_neighborhood(test, user_features, item_features, nz_test)\n",
    "        print(\"RMSE on test data: {}.\".format(rmse))\n",
    "    return item_features, user_features\n",
    "        \n",
    "item_features, user_features = neighborhood_model(train, \n",
    "                                                           test, \n",
    "                                                           gamma=0.013, \n",
    "                                                           num_epochs=5,\n",
    "                                                           num_features=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix factorization baseline latent factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn the matrix factorization using SGD...\n",
      "iter: 0, RMSE on training set: 1.0451849800830444.\n",
      "RMSE on test data: 1.0639182121388713.\n",
      "iter: 1, RMSE on training set: 1.0270426884752444.\n",
      "RMSE on test data: 1.0413497456278764.\n",
      "iter: 2, RMSE on training set: 1.0211761519110731.\n",
      "RMSE on test data: 1.0352123176231065.\n",
      "iter: 3, RMSE on training set: 1.0208435592623124.\n",
      "RMSE on test data: 1.034188081195767.\n",
      "iter: 4, RMSE on training set: 1.0187363115686565.\n",
      "RMSE on test data: 1.0316211853573893.\n",
      "iter: 5, RMSE on training set: 1.0165396836040579.\n",
      "RMSE on test data: 1.028323744336284.\n",
      "iter: 6, RMSE on training set: 1.016206591267179.\n",
      "RMSE on test data: 1.0282051412280042.\n",
      "iter: 7, RMSE on training set: 1.0159413256478451.\n",
      "RMSE on test data: 1.027585966051878.\n",
      "iter: 8, RMSE on training set: 1.0154202877541059.\n",
      "RMSE on test data: 1.0269840458153303.\n",
      "iter: 9, RMSE on training set: 1.0148271520226007.\n",
      "RMSE on test data: 1.0262495273140442.\n"
     ]
    }
   ],
   "source": [
    "def compute_error_v1(data, user_features, item_features, nz):\n",
    "    mse = 0   \n",
    "    for row, col in nz:\n",
    "        p = user_features[:, col]\n",
    "        q = item_features[:, row]\n",
    "        prediction = p.T.dot(q)\n",
    "        mse += (data[row, col] - prediction)**2\n",
    "    return np.sqrt(1.0 * mse / len(nz))\n",
    "\n",
    "def matrix_factorization_SGD_v1(train, \n",
    "                             test, \n",
    "                             num_features=20, \n",
    "                             gamma=0.05, \n",
    "                             lambda_user=0.1, \n",
    "                             lambda_item=0.7, \n",
    "                             num_epochs=10):     \n",
    "    \"\"\"matrix factorization by SGD.\"\"\"\n",
    "\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init matrix\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # find the non-zero ratings indices \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "\n",
    "    print(\"learn the matrix factorization using SGD...\")\n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # decrease step size\n",
    "        gamma /= 1.2\n",
    "\n",
    "        for d, n in nz_train:\n",
    "\n",
    "            q = item_features[:, d]\n",
    "            p = user_features[:, n]\n",
    "            prediction = p.T.dot(q)  \n",
    "            \n",
    "            error = train[d, n] - prediction\n",
    "            \n",
    "            # Update variables\n",
    "            item_features[:, d] += gamma * (error * p - lambda_item * q)\n",
    "            user_features[:, n] += gamma * (error * q - lambda_user * p)\n",
    "     \n",
    "        rmse = compute_error_v1(train, user_features, item_features, nz_train)\n",
    "        print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse)) \n",
    "        rmse = compute_error_v1(test, user_features, item_features, nz_test)\n",
    "        print(\"RMSE on test data: {}.\".format(rmse))\n",
    "    return item_features, user_features\n",
    "        \n",
    "item_features, user_features = matrix_factorization_SGD_baseline(train, \n",
    "                                                           test, \n",
    "                                                           gamma=0.01, \n",
    "                                                           lambda_user=0.1,\n",
    "                                                           lambda_item=0.5,\n",
    "                                                           num_epochs=10,\n",
    "                                                           num_features=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix factorization biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_biased(data, user_features, item_features, nz, user_bias, item_bias, global_mean):\n",
    "    mse = 0   \n",
    "    for d, n in nz:\n",
    "        p = user_features[:, n]\n",
    "        q = item_features[:, d]\n",
    "        base = global_mean + user_bias[n] + item_bias[d]\n",
    "        prediction = base + p.T.dot(q)\n",
    "        mse += (data[d, n] - prediction)**2\n",
    "    return np.sqrt(1.0 * mse / len(nz))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def matrix_factorization_SGD_biased(train, \n",
    "                             test, \n",
    "                             num_features=20, \n",
    "                             gamma=0.05, \n",
    "                             lambda_user_bias = 0.1,\n",
    "                             lambda_item_bias = 0.1,\n",
    "                             lambda_user=0.1, \n",
    "                             lambda_item=0.7, \n",
    "                             num_epochs=10):    \n",
    "    \"\"\"matrix factorization by SGD.\"\"\"\n",
    "\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init matrix\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # find the non-zero ratings indices \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "    \n",
    "    global_mean = train[train.nonzero()].mean()\n",
    "    user_bias = np.random.normal(scale=np.sqrt(2/num_features), size=train.shape[1])\n",
    "    item_bias = np.random.normal(scale=np.sqrt(2/num_features), size=train.shape[0])\n",
    "    \n",
    "    print(\"learn the matrix factorization using SGD...\")\n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # decrease step size\n",
    "        gamma /= 1.2\n",
    "\n",
    "        for d, n in nz_train:\n",
    "\n",
    "            q = item_features[:, d]\n",
    "            p = user_features[:, n]\n",
    "            base_prediction = global_mean + item_bias[d] + user_bias[n]\n",
    "            prediction =  base_prediction + p.T.dot(q)\n",
    "            error = train[d, n] - prediction\n",
    "            \n",
    "            # Update variables\n",
    "            user_bias[n] +=  gamma * (error - lambda_user_bias * user_bias[n])\n",
    "            item_bias[d] +=  gamma * (error - lambda_item_bias * item_bias[d])\n",
    "            item_features[:, d] += gamma * ((error * p - lambda_item * q))\n",
    "            user_features[:, n] += gamma * ((error * q - lambda_user * p))\n",
    "     \n",
    "        rmse = compute_error_v2(train, user_features, item_features, nz_train, user_bias, item_bias, global_mean)\n",
    "        print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse)) # \n",
    "        rmse = compute_error_v2(test, user_features, item_features, nz_test, user_bias, item_bias, global_mean)\n",
    "        print(\"RMSE on test data: {}.\".format(rmse))\n",
    "    return item_features, user_features, user_bias, item_bias, global_mean\n",
    "\n",
    "item_features, user_features, user_bias, item_bias, global_bias = matrix_factorization_SGD_biased(\n",
    "    train, \n",
    "    test, \n",
    "    gamma=0.02, \n",
    "    num_epochs=20,\n",
    "    num_features=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix factorization SVD++ (VERY SLOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnz_users_train = []\n",
    "for user in range(train.shape[1]):\n",
    "    nnz_users_train.append(train[:, user].nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_error_v3(data, \n",
    "                     user_features, \n",
    "                     item_features, \n",
    "                     nz, \n",
    "                     user_bias, \n",
    "                     item_bias, \n",
    "                     global_mean, \n",
    "                     yj,\n",
    "                     nnz_user):\n",
    "    mse = 0   \n",
    "    feedbacks = []\n",
    "    for user in range(user_features.shape[1]):\n",
    "        nz_row, _ = nnz_user[user]\n",
    "        implicit_feedback = np.sum(yj[nz_row, :], axis=0)\n",
    "        if len(nz_row) > 0:\n",
    "            implicit_feedback /= np.sqrt(len(nz_row))\n",
    "        feedbacks.append(implicit_feedback)\n",
    "    \n",
    "    for row, col in nz:\n",
    "        user = col\n",
    "        implicit_feedback = feedbacks[user]\n",
    "        p = user_features[:, col] + implicit_feedback\n",
    "        q = item_features[:, row]\n",
    "        base = global_mean + user_bias[col] + item_bias[row]\n",
    "        prediction = base + q.dot(p.T)\n",
    "        mse += (data[row, col] - prediction)**2\n",
    "    return np.sqrt(1.0 * mse / len(nz))\n",
    "\n",
    "\n",
    "\n",
    "# SVD++\n",
    "def matrix_factorization_SGD_v3(train, \n",
    "                             test, \n",
    "                             nnz_users_train,\n",
    "                             num_features=20, \n",
    "                             gamma=0.05, \n",
    "                             lambda_user=0.1, \n",
    "                             lambda_item=0.7,\n",
    "                             lambda_yj=0.1,\n",
    "                             lambda_user_bias=0.1,\n",
    "                             lambda_item_bias=0.1,\n",
    "                             num_epochs=5):\n",
    "    \n",
    "    \n",
    "    #nz_train, nz_item_userindices, nz_user_itemindices = build_index_groups(train)\n",
    "        \n",
    "\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init matrix\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # find the non-zero ratings indices \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "    \n",
    "    global_mean = train[train.nonzero()].mean()\n",
    "    user_bias = np.random.normal(scale=0.00, size=train.shape[1])\n",
    "    item_bias = np.random.normal(scale=0.00, size=train.shape[0])\n",
    "    \n",
    "    yj = np.random.normal(scale=0.1, size=(train.shape[0], num_features))\n",
    "    \n",
    "    #nnz_users_train = []\n",
    "    #for user in range(train.shape[1]):\n",
    "    #    nnz_users_train.append(train[:, user].nonzero())\n",
    "    \n",
    "    \n",
    "    print(\"learn the matrix factorization using SGD...\")\n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # decrease step size\n",
    "        gamma /= 1.2\n",
    "    \n",
    "        iters = 0\n",
    "        \n",
    "        for d, n in nz_train:\n",
    "            iters += 1\n",
    "            if iters % 200000 == 0:\n",
    "                print(iters)\n",
    "            \n",
    "            # Calculate implicit feedback, expensive!\n",
    "            nz_row, _ = nnz_users_train[n]\n",
    "            lSqrt = np.sqrt(len(nz_row))\n",
    "            implicit_feedback = np.sum(yj[nz_row, :], axis=0)\n",
    "            implicit_feedback /= lSqrt\n",
    "            \n",
    "            q = item_features[:, d]\n",
    "            p = user_features[:, n] + implicit_feedback\n",
    "            base_prediction = global_mean + item_bias[d] + user_bias[n]\n",
    "            prediction = base_prediction + p.T.dot(q)\n",
    "            error = train[d, n] - prediction \n",
    "            \n",
    "            \n",
    "            # Update variables\n",
    "            user_bias[n] +=  gamma * (error - lambda_user_bias * user_bias[n])\n",
    "            item_bias[d] +=  gamma * (error - lambda_item_bias * item_bias[d])\n",
    "            \n",
    "            \n",
    "            # Update implicit feedback, expensive!\n",
    "            yj[nz_row, :] += gamma * (error * q / lSqrt - lambda_yj * yj[nz_row, :])\n",
    "            \n",
    "            item_features[:, d] += gamma * ((error * p - lambda_item * q))\n",
    "            user_features[:, n] += gamma * ((error * q - lambda_user * p)) \n",
    "     \n",
    "        rmse = compute_error_v3(train, user_features, item_features, nz_train, user_bias, item_bias, global_mean, yj, nnz_users_train)\n",
    "        print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse)) \n",
    "        rmse = compute_error_v3(test, user_features, item_features, nz_test, user_bias, item_bias, global_mean, yj, nnz_users_train)\n",
    "        print(\"RMSE on test data: {}.\".format(rmse))\n",
    "    return item_features, user_features, user_bias, item_bias, global_mean\n",
    "\n",
    " \n",
    "# trying to beat : 0.9390441348636658\n",
    "#item_features, user_features, user_bias, item_bias, global_mean = matrix_factorization_SGD_v3(train, \n",
    "#                                                                                              test, \n",
    "#                                                                                              nnz_users_train,\n",
    "#                                                                                              gamma=0.02, \n",
    "##                                                                                              num_features=17, \n",
    "#                                                                                              lambda_yj=0.001, \n",
    "#                                                                                              lambda_user=0.1, \n",
    "#                                                                                              lambda_item=0.7, \n",
    "#                                                                                              lambda_user_bias=0.1, \n",
    "#                                                                                              lambda_item_bias=0.1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying params gamma: 0.02, num_features: 25, lambda_yj: 0.1, lambda_user: 0.5,lambda_item: 0.7,user_bias: 0.1,item_bias: 0.1\n",
      "learn the matrix factorization using SGD...\n",
      "200000\n",
      "400000\n",
      "600000\n",
      "800000\n",
      "1000000\n",
      "iter: 0, RMSE on training set: 0.9979341272498358.\n",
      "RMSE on test data: 1.0068635381812987.\n",
      "200000\n",
      "400000\n",
      "600000\n",
      "800000\n",
      "1000000\n",
      "iter: 1, RMSE on training set: 0.9951946033107628.\n",
      "RMSE on test data: 1.004055564021264.\n",
      "Trying params gamma: 0.02, num_features: 25, lambda_yj: 0.01, lambda_user: 0.5,lambda_item: 0.7,user_bias: 0.1,item_bias: 0.1\n",
      "learn the matrix factorization using SGD...\n",
      "200000\n",
      "400000\n",
      "600000\n",
      "800000\n",
      "1000000\n",
      "iter: 0, RMSE on training set: 0.9980051691562559.\n",
      "RMSE on test data: 1.006946355877238.\n",
      "200000\n",
      "400000\n",
      "600000\n",
      "800000\n",
      "1000000\n",
      "iter: 1, RMSE on training set: 0.9951967650371744.\n",
      "RMSE on test data: 1.0040488476293719.\n",
      "Trying params gamma: 0.02, num_features: 25, lambda_yj: 0.001, lambda_user: 0.5,lambda_item: 0.7,user_bias: 0.1,item_bias: 0.1\n",
      "learn the matrix factorization using SGD...\n",
      "200000\n",
      "400000\n",
      "600000\n",
      "800000\n",
      "1000000\n",
      "iter: 0, RMSE on training set: 0.9980989651017067.\n",
      "RMSE on test data: 1.007029736528982.\n",
      "200000\n",
      "400000\n",
      "600000\n",
      "800000\n",
      "1000000\n",
      "iter: 1, RMSE on training set: 0.9952331630492218.\n",
      "RMSE on test data: 1.0040487695154852.\n",
      "Trying params gamma: 0.02, num_features: 25, lambda_yj: 0.1, lambda_user: 0.5,lambda_item: 0.7,user_bias: 0.01,item_bias: 0.1\n",
      "learn the matrix factorization using SGD...\n",
      "200000\n",
      "400000\n",
      "600000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-39aad79c0bcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m                                  num_epochs=2)   \n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-39aad79c0bcf>\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m(train, test)\u001b[0m\n\u001b[1;32m     29\u001b[0m                                  \u001b[0mlambda_user_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lambda_user_bias'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                  \u001b[0mlambda_item_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lambda_item_bias'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                                  num_epochs=2)   \n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-dd9ca988b2c6>\u001b[0m in \u001b[0;36mmatrix_factorization_SGD_v3\u001b[0;34m(train, test, nnz_users_train, num_features, gamma, lambda_user, lambda_item, lambda_yj, lambda_user_bias, lambda_item_bias, num_epochs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m# Update implicit feedback, expensive!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0myj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnz_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlSqrt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlambda_yj\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0myj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnz_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mitem_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlambda_item\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "def grid_search(train, test):\n",
    "    param_grid = {'gamma': [0.02], \n",
    "                  'num_features' : [25],\n",
    "                  'lambda_user': [0.5, 0.3, 0.1, 0.01],\n",
    "                  'lambda_item': [0.7,0.3, 0.1],\n",
    "                  'lambda_user_bias': [0.1, 0.01],\n",
    "                  'lambda_item_bias': [0.1, 0.01],\n",
    "                  'lambda_yj' : [0.1, 0.01, 0.001] }\n",
    "    grid = ParameterGrid(param_grid)\n",
    "    for g in grid:\n",
    "        print(\"Trying params gamma: {}, num_features: {}, lambda_yj: {}, lambda_user: {},lambda_item: {},user_bias: {},item_bias: {}\"\\\n",
    "                  .format(g['gamma'],\n",
    "                           g['num_features'],\n",
    "                           g['lambda_yj'],\n",
    "                           g['lambda_user'],\n",
    "                           g['lambda_item'],\n",
    "                           g['lambda_user_bias'],\n",
    "                           g['lambda_item_bias']))\n",
    "        \n",
    "        matrix_factorization_SGD_v3(train, \n",
    "                                 test, \n",
    "                                 nnz_users_train,\n",
    "                                 num_features=g['num_features'], \n",
    "                                 gamma=g['gamma'], \n",
    "                                 lambda_yj=g['lambda_yj'],\n",
    "                                 lambda_user=g['lambda_user'],\n",
    "                                 lambda_item=g['lambda_item'],\n",
    "                                 lambda_user_bias=g['lambda_user_bias'],\n",
    "                                 lambda_item_bias=g['lambda_item_bias'],\n",
    "                                 num_epochs=2)   \n",
    "        \n",
    "grid_search(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SURPISE FRAMEWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import SVDpp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nonzero elements in origial data:1176952\n",
      "Total number of nonzero elements in train data:1059410\n",
      "Total number of nonzero elements in test data:117463\n"
     ]
    }
   ],
   "source": [
    "valid_ratings, train, test, valdid_users, valid_items = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=10, p_test=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(line_format='user item rating', sep=',')\n",
    "data = Dataset.load_from_file(file_path=\"./data/train_surprise.csv\",reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"./data/de_data_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['user'] = data_df['Id'].str.split('_').str[0].apply(lambda x: x[1:])\n",
    "data_df['item'] = data_df['Id'].str.split('_').str[1].apply(lambda x: x[1:])\n",
    "data_df = data_df.rename(columns={'Prediction':'rating'})\n",
    "data_df = data_df[['user','item','rating']]\n",
    "data_df['user'] = data_df['user'].astype('int')\n",
    "data_df['item'] = data_df['item'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_per_item = data_df.groupby('item').count().rename(columns={'rating':'ratings'})\n",
    "bad_items = ratings_per_item[ratings_per_item['ratings'] < 100]['ratings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "1     3\n",
       "2    13\n",
       "3    10\n",
       "4     1\n",
       "5    13\n",
       "Name: ratings, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_per_user = data_df.groupby('user').count().rename(columns={'rating':'ratings'})\n",
    "bad_users = ratings_per_user[ratings_per_user['ratings'] < 15]['ratings']\n",
    "bad_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean rating per user\n",
    "mean_rating_per_user = data_df.groupby('user').mean()[['rating']]\n",
    "# Calculate mean rating per item\n",
    "mean_rating_per_user = data_df.groupby('item').mean()[['rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>534101</th>\n",
       "      <td>355</td>\n",
       "      <td>459</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695462</th>\n",
       "      <td>7958</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252428</th>\n",
       "      <td>8764</td>\n",
       "      <td>210</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201403</th>\n",
       "      <td>4997</td>\n",
       "      <td>176</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696428</th>\n",
       "      <td>131</td>\n",
       "      <td>595</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  item  rating\n",
       "534101   355   459       4\n",
       "695462  7958   594       4\n",
       "252428  8764   210       5\n",
       "201403  4997   176       4\n",
       "696428   131   595       5"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data_df = data_df.loc[~data_df['user'].isin(bad_users.index)]\n",
    "valid_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid_data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-6aadf6088941>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrating_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_data_df' is not defined"
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(valid_data_df, reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVDpp on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0404  1.0329  1.0417  1.0368  1.0513  1.0406  0.0061  \n",
      "MAE (testset)     0.8305  0.8304  0.8338  0.8346  0.8398  0.8338  0.0034  \n",
      "Fit time          14.08   19.88   17.20   14.74   15.18   16.22   2.11    \n",
      "Test time         0.39    0.42    0.32    0.32    0.36    0.36    0.04    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.04044451, 1.03293874, 1.04166871, 1.03677596, 1.05130403]),\n",
       " 'test_mae': array([0.83048483, 0.83044262, 0.83383133, 0.83456013, 0.83984313]),\n",
       " 'fit_time': (14.08045506477356,\n",
       "  19.876182079315186,\n",
       "  17.201558113098145,\n",
       "  14.742361068725586,\n",
       "  15.178871154785156),\n",
       " 'test_time': (0.3854358196258545,\n",
       "  0.41551899909973145,\n",
       "  0.32459592819213867,\n",
       "  0.32497620582580566,\n",
       "  0.36459875106811523)}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Algorithm: if valid user, then use SVD otherwise use item mean\n",
    "# 'test_rmse': array([1.02740995, 1.02443418, 1.02385119, 1.02513035, 1.02606437]),\n",
    "#array([1.02944142, 1.0342882 , 1.04817627, 1.03784618, 1.04570061])\n",
    "\n",
    "#\n",
    "algo = SVDpp()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.006269249267568\n",
      "{'n_factors': 10, 'n_epochs': 5, 'lr_all': 0.01, 'reg_all': 0.2}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_factors': [10], 'n_epochs': [5], 'lr_all': [0.01],\n",
    "              'reg_all': [0.2]}\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(data)\n",
    "algo = gs.best_estimator['rmse']\n",
    "print(gs.best_score['rmse']) # 1.0162184499060751\n",
    "print(gs.best_params['rmse'])\n",
    "#cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "#cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0272  1.0226  1.0261  1.0256  1.0272  1.0257  0.0017  \n",
      "MAE (testset)     0.8160  0.8130  0.8142  0.8142  0.8147  0.8144  0.0010  \n",
      "Fit time          58.20   64.63   66.81   66.94   64.89   64.29   3.19    \n",
      "Test time         3.70    2.78    2.99    3.59    3.00    3.21    0.36    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.02719875, 1.02261752, 1.02607338, 1.02562439, 1.02721876]),\n",
       " 'test_mae': array([0.81597463, 0.81300227, 0.81424311, 0.81421808, 0.81473755]),\n",
       " 'fit_time': (58.19613003730774,\n",
       "  64.63061690330505,\n",
       "  66.8094711303711,\n",
       "  66.94464302062988,\n",
       "  64.89107584953308),\n",
       " 'test_time': (3.6983349323272705,\n",
       "  2.783917188644409,\n",
       "  2.9863617420196533,\n",
       "  3.5879390239715576,\n",
       "  3.003139019012451)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-16-5bf6ad3976e4>\", line 2, in <module>\n",
      "    cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/surprise/model_selection/validation.py\", line 101, in cross_validate\n",
      "    out = Parallel(n_jobs=n_jobs, pre_dispatch=pre_dispatch)(delayed_list)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\", line 920, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/surprise/model_selection/validation.py\", line 164, in fit_and_score\n",
      "    algo.fit(trainset)\n",
      "  File \"surprise/prediction_algorithms/matrix_factorization.pyx\", line 397, in surprise.prediction_algorithms.matrix_factorization.SVDpp.fit\n",
      "  File \"surprise/prediction_algorithms/matrix_factorization.pyx\", line 447, in surprise.prediction_algorithms.matrix_factorization.SVDpp.sgd\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/surprise/trainset.py\", line 190, in all_ratings\n",
      "    yield u, i, r\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algo = SVDpp()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x106738048>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLENDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from surprise import KNNWithMeans\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "itertuples not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-d227ba477f75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'item'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrating_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_surprise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/surprise/dataset.py\u001b[0m in \u001b[0;36mload_from_df\u001b[0;34m(cls, df, reader)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \"\"\"\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDatasetAutoFolds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_ratings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/surprise/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ratings_file, reader, df)\u001b[0m\n\u001b[1;32m    288\u001b[0m             self.raw_ratings = [(uid, iid, float(r) + self.reader.offset, None)\n\u001b[1;32m    289\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                                 self.df.itertuples(index=False)]\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Must specify ratings file or dataframe.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: itertuples not found"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"./data/de_data_train.csv\")\n",
    "data_df['user'] = data_df['Id'].str.split('_').str[0].apply(lambda x: x[1:])\n",
    "data_df['item'] = data_df['Id'].str.split('_').str[1].apply(lambda x: x[1:])\n",
    "data_df = data_df.rename(columns={'Prediction':'rating'})\n",
    "data_df = data_df[['user','item','rating']]\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "train_surprise = Dataset.load_from_df(train, reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_and_val, test = train_test_split(data_df, test_size=0.1)\n",
    "train, val = train_test_split(train_and_val, test_size=0.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(932145, 3)\n",
      "(117696, 3)\n",
      "(127111, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "#t = \n",
    "train_surprise = Dataset.load_from_df(train, reader=reader).build_full_trainset()\n",
    "val_surprise = Dataset.load_from_df(val, reader=reader).build_full_trainset()\n",
    "test_surprise = Dataset.load_from_df(test, reader=reader).build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainset, testset = train_test_split(data, test_size=.15)\n",
    "#trainset, valset = train_test_split(trainset, test_size=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from surprise.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(train_surprise[['user', 'item']], train_surprise['rating'], test_size=0.12, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_mean = train_surprise.global_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_dataset = \"./data/de_data_train.csv\"\n",
    "#ratings = load_data(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_mean = trainset.global_mean\n",
    "#global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for user in range(num_users):\n",
    "#    user_ratings_train = train[:, user]\n",
    "#    nnz_train = user_ratings_train[user_ratings_train.nonzero()]\n",
    "##    if nnz_train.shape[0] == 0:\n",
    "#        continue\n",
    "#    user_mean = nnz_train.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1a806c9278>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_algo = SVD()\n",
    "svd_algo.fit(train_surprise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0212879135307333"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred1 = svd_algo.test(val_surprise.build_testset())\n",
    "accuracy.rmse(val_pred1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.028259592835307"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred1 = svd_algo.test(test_surprise.build_testset())\n",
    "accuracy.rmse(test_pred1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x1a806c9f28>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_algo = KNNWithMeans(k=20, sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "knn_algo.fit(train_surprise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9925848959175658"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred2 = knn_algo.test(val_surprise.build_testset())\n",
    "accuracy.rmse(val_pred2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9987039317656763"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred2 = knn_algo.test(test_surprise.build_testset())\n",
    "accuracy.rmse(test_pred2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slope One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SlopeOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.slope_one.SlopeOne at 0x1a2f445b38>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sloopOne_algo = SlopeOne()\n",
    "sloopOne_algo.fit(train_surprise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.996848067147983"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred3 = sloopOne_algo.test(val_surprise.build_testset())\n",
    "accuracy.rmse(val_pred3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0009650123894438"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred3 = sloopOne_algo.test(test_surprise.build_testset())\n",
    "accuracy.rmse(test_pred3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.NMF at 0x1a1e446128>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_algo = NMF()\n",
    "nmf_algo.fit(train_surprise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.008878052929819"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred4 = nmf_algo.test(val_surprise.build_testset())\n",
    "accuracy.rmse(val_pred4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0124810976561212"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred4 = nmf_algo.test(test_surprise.build_testset())\n",
    "accuracy.rmse(test_pred4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import CoClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.co_clustering.CoClustering at 0x1a1db61898>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coc_algo = CoClustering()\n",
    "coc_algo.fit(train_surprise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0079445928837023"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred5 = coc_algo.test(val_surprise.build_testset())\n",
    "accuracy.rmse(val_pred5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0119444558614055"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred5 = coc_algo.test(test_surprise.build_testset())\n",
    "accuracy.rmse(test_pred5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import BaselineOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.baseline_only.BaselineOnly at 0x1a3ccdb9e8>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_algo = BaselineOnly()\n",
    "baseline_algo.fit(train_surprise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9959278867152633"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred6 = baseline_algo.test(val_surprise.build_testset())\n",
    "accuracy.rmse(val_pred6, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0001522028440322"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred6 = baseline_algo.test(test_surprise.build_testset())\n",
    "accuracy.rmse(test_pred6, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "x1_train = pd.Series(list(map(lambda x: x.est, val_pred1)))\n",
    "x2_train = pd.Series(list(map(lambda x: x.est, val_pred2)))\n",
    "x3_train = pd.Series(list(map(lambda x: x.est, val_pred3)))\n",
    "x4_train = pd.Series(list(map(lambda x: x.est, val_pred4)))\n",
    "x5_train = pd.Series(list(map(lambda x: x.est, val_pred5)))\n",
    "x6_train = pd.Series(list(map(lambda x: x.est, val_pred5)))\n",
    "\n",
    "X_train = pd.concat([x1_train, x2_train, x3_train, x4_train, x5_train, x6_train], axis=1)\n",
    "\n",
    "x1_test = pd.Series(list(map(lambda x: x.est, test_pred1)))\n",
    "x2_test = pd.Series(list(map(lambda x: x.est, test_pred2)))\n",
    "x3_test = pd.Series(list(map(lambda x: x.est, test_pred3)))\n",
    "x4_test = pd.Series(list(map(lambda x: x.est, test_pred4)))\n",
    "x5_test = pd.Series(list(map(lambda x: x.est, test_pred5)))\n",
    "x6_test = pd.Series(list(map(lambda x: x.est, test_pred6)))\n",
    "\n",
    "\n",
    "X_test = pd.concat([x1_test, x2_test, x3_test, x4_test, x5_test, x6_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = []\n",
    "for r in val_surprise.all_ratings():\n",
    "    y_train.append(r[2])\n",
    "clf = Ridge()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "for r in test_surprise.all_ratings():\n",
    "    y_test.append(r[2])\n",
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.23813891, 4.03341585, 4.0073263 , ..., 4.52281724, 3.67256192,\n",
       "       3.66239338])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9907173273162181"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-223-19ea7c6f652f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mcreate_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-223-19ea7c6f652f>\u001b[0m in \u001b[0;36mcreate_submission\u001b[0;34m(predictions)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/submission_rows'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "def create_submission(predictions):\n",
    "    out = open(\"submission.csv\",\"w\")\n",
    "    out.write('Id,Prediction\\n')\n",
    "    with open('./data/submission_rows') as samples:\n",
    "        for prediction in predictions:\n",
    "            tmp = sample.split('_')\n",
    "            row = int(tmp[0][1:].strip())\n",
    "            col = int(tmp[1][1:].strip())\n",
    "            p = int(np.rint(prediction))\n",
    "            p = 5 if prediction == 6 else prediction\n",
    "            p_string = \"r{}_c{},{}\\n\".format(row, col, p)\n",
    "            out.write(p_string)        \n",
    "    out.close()\n",
    "create_submission(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user item\n",
       "0   37    1\n",
       "1   73    1\n",
       "2  156    1\n",
       "3  160    1\n",
       "4  248    1"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_rows_df = pd.read_csv(\"./data/submission_rows\")\n",
    "submission_rows_df.head()\n",
    "submission_rows_df['user'] = submission_rows_df['Id'].str.split('_').str[0].apply(lambda x: x[1:])\n",
    "submission_rows_df['item'] = submission_rows_df['Id'].str.split('_').str[1].apply(lambda x: x[1:])\n",
    "submission_rows_df = submission_rows_df[['user','item']]\n",
    "submission_rows_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid='37', iid='1', r_ui=None, est=3.482571753635543, details={'was_impossible': False})"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_algo.predict(submission_rows_df['user'][0], submission_rows_df['item'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "[3.49832986 3.4677595  3.11389886 ... 4.35145133 4.08664604 2.32842242]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.002695447473367"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_and_predict(algo, train, val, test):\n",
    "    algo.fit(train)\n",
    "    val_pred = algo.test(val.build_testset())\n",
    "    test_pred = algo.test(test.build_testset())\n",
    "    return pd.Series(list(map(lambda x: x.est, val_pred))), pd.Series(list(map(lambda x: x.est, test_pred)))\n",
    "\n",
    "\n",
    "models = [#SVD(), \n",
    "          #KNNWithMeans(k=20, sim_options={'name': 'pearson_baseline', 'user_based': False}), \n",
    "          #SlopeOne(),\n",
    "          #NMF(),\n",
    "          #CoClustering(),\n",
    "          BaselineOnly(),\n",
    "         ]\n",
    "\n",
    "X_train = pd.DataFrame()\n",
    "X_test = pd.DataFrame()\n",
    "for model in models:\n",
    "    val_pred, test_pred = train_and_predict(model, train_surprise, val_surprise, test_surprise)\n",
    "    X_train = pd.concat([X_train, val_pred], axis=1)\n",
    "    X_test = pd.concat([X_test, test_pred], axis=1)\n",
    "    \n",
    "    \n",
    "y_train = []\n",
    "for r in val_surprise.all_ratings():\n",
    "    y_train.append(r[2])\n",
    "clf = Ridge()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_test = []\n",
    "for r in test_surprise.all_ratings():\n",
    "    y_test.append(r[2])\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(pred)\n",
    "\n",
    "np.sqrt(mean_squared_error(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
