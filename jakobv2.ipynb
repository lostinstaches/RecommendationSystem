{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNBaseline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from surprise import SlopeOne\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data_df = pd.read_csv(\"./data/de_data_train.csv\")\n",
    "    data_df['user'] = data_df['Id'].str.split('_').str[0].apply(lambda x: int(x[1:]))\n",
    "    data_df['item'] = data_df['Id'].str.split('_').str[1].apply(lambda x: int(x[1:]))\n",
    "    data_df = data_df.rename(columns={'Prediction':'rating'})\n",
    "    data_df = data_df[['user','item','rating']]\n",
    "    return data_df\n",
    "def create_submission(model):\n",
    "    print(\"Predicting...\")\n",
    "    out = open(\"submission.csv\",\"w\")\n",
    "    out.write('Id,Prediction\\n')\n",
    "    with open('./data/submission_rows') as samples:\n",
    "        for i, sample in enumerate(samples):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            if i == 10000:\n",
    "                print(i)\n",
    "            tmp = sample.split('_')\n",
    "            item = int(tmp[0][1:].strip())\n",
    "            user = int(tmp[1][1:].strip())\n",
    "            p = model.predict(item, user)\n",
    "            p_string = \"r{}_c{},{}\\n\".format(item, user, p)\n",
    "            out.write(p_string)        \n",
    "    out.close()\n",
    "def get_submission_rows():\n",
    "    users = []\n",
    "    items = []\n",
    "    with open('./data/submission_rows') as samples:\n",
    "        for i, sample in enumerate(samples):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            tmp = sample.split('_')\n",
    "            item = int(tmp[0][1:].strip())\n",
    "            user = int(tmp[1][1:].strip())\n",
    "            users.append(user)\n",
    "            items.append(item)\n",
    "    return users, items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user  item  rating\n",
      "0    44     1       4\n",
      "1    61     1       3\n",
      "2    67     1       4\n",
      "3    72     1       3\n",
      "4    86     1       5\n"
     ]
    }
   ],
   "source": [
    "data = load_data()\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(data, param_grid, algo, folds):\n",
    "    gs = GridSearchCV(algo, \n",
    "                  param_grid, \n",
    "                  measures=['rmse', 'mae'], \n",
    "                  return_train_measures=True,\n",
    "                  cv=folds, \n",
    "                  joblib_verbose=1)\n",
    "    gs.fit(data)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed: 24.9min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_epochs': [30],# 10, 15], \n",
    "              'n_factors': [10, 20, 30, 40],# 10, 15, 20, 25, 30], \n",
    "              'reg_all': [0.1, 0.2],# 0.01, 0.001], \n",
    "              'lr_all': [0.01]}#, 0.01, 0.001]}\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "surprise_data = Dataset.load_from_df(data, reader=reader)\n",
    "gs = grid_search(data=surprise_data, param_grid=param_grid, algo=SVD,folds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_rmse</th>\n",
       "      <th>split0_train_rmse</th>\n",
       "      <th>split1_test_rmse</th>\n",
       "      <th>split1_train_rmse</th>\n",
       "      <th>split2_test_rmse</th>\n",
       "      <th>split2_train_rmse</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>mean_train_rmse</th>\n",
       "      <th>std_train_rmse</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_test_mae</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_time</th>\n",
       "      <th>std_test_time</th>\n",
       "      <th>params</th>\n",
       "      <th>param_n_epochs</th>\n",
       "      <th>param_n_factors</th>\n",
       "      <th>param_reg_all</th>\n",
       "      <th>param_lr_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.004753</td>\n",
       "      <td>0.982623</td>\n",
       "      <td>1.004574</td>\n",
       "      <td>0.981093</td>\n",
       "      <td>1.004562</td>\n",
       "      <td>0.980840</td>\n",
       "      <td>1.004630</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.981519</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>29.696937</td>\n",
       "      <td>0.280583</td>\n",
       "      <td>5.099243</td>\n",
       "      <td>0.500935</td>\n",
       "      <td>{'n_epochs': 30, 'n_factors': 10, 'reg_all': 0...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.013797</td>\n",
       "      <td>1.003183</td>\n",
       "      <td>1.013966</td>\n",
       "      <td>1.001992</td>\n",
       "      <td>1.014345</td>\n",
       "      <td>1.002397</td>\n",
       "      <td>1.014036</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>1.002524</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>29.376848</td>\n",
       "      <td>0.950957</td>\n",
       "      <td>5.155132</td>\n",
       "      <td>0.714383</td>\n",
       "      <td>{'n_epochs': 30, 'n_factors': 10, 'reg_all': 0...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.002719</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>1.002611</td>\n",
       "      <td>0.971679</td>\n",
       "      <td>1.004633</td>\n",
       "      <td>0.975813</td>\n",
       "      <td>1.003321</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.973914</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>34.636455</td>\n",
       "      <td>0.762781</td>\n",
       "      <td>5.358722</td>\n",
       "      <td>0.613559</td>\n",
       "      <td>{'n_epochs': 30, 'n_factors': 20, 'reg_all': 0...</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.013796</td>\n",
       "      <td>1.003170</td>\n",
       "      <td>1.013965</td>\n",
       "      <td>1.001979</td>\n",
       "      <td>1.014345</td>\n",
       "      <td>1.002386</td>\n",
       "      <td>1.014035</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>1.002511</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>39.812804</td>\n",
       "      <td>1.492780</td>\n",
       "      <td>5.867776</td>\n",
       "      <td>2.000901</td>\n",
       "      <td>{'n_epochs': 30, 'n_factors': 20, 'reg_all': 0...</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.001658</td>\n",
       "      <td>0.967305</td>\n",
       "      <td>1.001722</td>\n",
       "      <td>0.965635</td>\n",
       "      <td>1.002474</td>\n",
       "      <td>0.967466</td>\n",
       "      <td>1.001951</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.966802</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>45.022645</td>\n",
       "      <td>2.179515</td>\n",
       "      <td>5.971200</td>\n",
       "      <td>0.501501</td>\n",
       "      <td>{'n_epochs': 30, 'n_factors': 30, 'reg_all': 0...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.013795</td>\n",
       "      <td>1.003158</td>\n",
       "      <td>1.013965</td>\n",
       "      <td>1.001966</td>\n",
       "      <td>1.014344</td>\n",
       "      <td>1.002372</td>\n",
       "      <td>1.014034</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>1.002499</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>49.393922</td>\n",
       "      <td>2.666508</td>\n",
       "      <td>6.304444</td>\n",
       "      <td>0.635659</td>\n",
       "      <td>{'n_epochs': 30, 'n_factors': 30, 'reg_all': 0...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.001015</td>\n",
       "      <td>0.961391</td>\n",
       "      <td>1.001477</td>\n",
       "      <td>0.960546</td>\n",
       "      <td>1.001364</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>1.001285</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.960840</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>48.691504</td>\n",
       "      <td>1.955575</td>\n",
       "      <td>4.526827</td>\n",
       "      <td>0.200685</td>\n",
       "      <td>{'n_epochs': 30, 'n_factors': 40, 'reg_all': 0...</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.013794</td>\n",
       "      <td>1.003144</td>\n",
       "      <td>1.013963</td>\n",
       "      <td>1.001955</td>\n",
       "      <td>1.014343</td>\n",
       "      <td>1.002360</td>\n",
       "      <td>1.014033</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>1.002486</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>63.067683</td>\n",
       "      <td>4.793341</td>\n",
       "      <td>7.632247</td>\n",
       "      <td>2.932391</td>\n",
       "      <td>{'n_epochs': 30, 'n_factors': 40, 'reg_all': 0...</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   split0_test_rmse  split0_train_rmse  split1_test_rmse  split1_train_rmse  \\\n",
       "0          1.004753           0.982623          1.004574           0.981093   \n",
       "1          1.013797           1.003183          1.013966           1.001992   \n",
       "2          1.002719           0.974249          1.002611           0.971679   \n",
       "3          1.013796           1.003170          1.013965           1.001979   \n",
       "4          1.001658           0.967305          1.001722           0.965635   \n",
       "5          1.013795           1.003158          1.013965           1.001966   \n",
       "6          1.001015           0.961391          1.001477           0.960546   \n",
       "7          1.013794           1.003144          1.013963           1.001955   \n",
       "\n",
       "   split2_test_rmse  split2_train_rmse  mean_test_rmse  std_test_rmse  \\\n",
       "0          1.004562           0.980840        1.004630       0.000087   \n",
       "1          1.014345           1.002397        1.014036       0.000229   \n",
       "2          1.004633           0.975813        1.003321       0.000929   \n",
       "3          1.014345           1.002386        1.014035       0.000230   \n",
       "4          1.002474           0.967466        1.001951       0.000371   \n",
       "5          1.014344           1.002372        1.014034       0.000229   \n",
       "6          1.001364           0.960584        1.001285       0.000196   \n",
       "7          1.014343           1.002360        1.014033       0.000229   \n",
       "\n",
       "   mean_train_rmse  std_train_rmse      ...       rank_test_mae  \\\n",
       "0         0.981519        0.000788      ...                   4   \n",
       "1         1.002524        0.000494      ...                   8   \n",
       "2         0.973914        0.001704      ...                   3   \n",
       "3         1.002511        0.000494      ...                   7   \n",
       "4         0.966802        0.000828      ...                   2   \n",
       "5         1.002499        0.000495      ...                   6   \n",
       "6         0.960840        0.000390      ...                   1   \n",
       "7         1.002486        0.000494      ...                   5   \n",
       "\n",
       "   mean_fit_time  std_fit_time  mean_test_time  std_test_time  \\\n",
       "0      29.696937      0.280583        5.099243       0.500935   \n",
       "1      29.376848      0.950957        5.155132       0.714383   \n",
       "2      34.636455      0.762781        5.358722       0.613559   \n",
       "3      39.812804      1.492780        5.867776       2.000901   \n",
       "4      45.022645      2.179515        5.971200       0.501501   \n",
       "5      49.393922      2.666508        6.304444       0.635659   \n",
       "6      48.691504      1.955575        4.526827       0.200685   \n",
       "7      63.067683      4.793341        7.632247       2.932391   \n",
       "\n",
       "                                              params  param_n_epochs  \\\n",
       "0  {'n_epochs': 30, 'n_factors': 10, 'reg_all': 0...              30   \n",
       "1  {'n_epochs': 30, 'n_factors': 10, 'reg_all': 0...              30   \n",
       "2  {'n_epochs': 30, 'n_factors': 20, 'reg_all': 0...              30   \n",
       "3  {'n_epochs': 30, 'n_factors': 20, 'reg_all': 0...              30   \n",
       "4  {'n_epochs': 30, 'n_factors': 30, 'reg_all': 0...              30   \n",
       "5  {'n_epochs': 30, 'n_factors': 30, 'reg_all': 0...              30   \n",
       "6  {'n_epochs': 30, 'n_factors': 40, 'reg_all': 0...              30   \n",
       "7  {'n_epochs': 30, 'n_factors': 40, 'reg_all': 0...              30   \n",
       "\n",
       "   param_n_factors  param_reg_all  param_lr_all  \n",
       "0               10            0.1          0.01  \n",
       "1               10            0.2          0.01  \n",
       "2               20            0.1          0.01  \n",
       "3               20            0.2          0.01  \n",
       "4               30            0.1          0.01  \n",
       "5               30            0.2          0.01  \n",
       "6               40            0.1          0.01  \n",
       "7               40            0.2          0.01  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(gs.cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0033069244262036"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(gs.cv_results).to_csv('svd_train_v4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import Rating\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user: integer (nullable = true)\n",
      " |-- item: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([ StructField(\"user\", IntegerType(), True)\\\n",
    "                       ,StructField(\"item\", IntegerType(), True)\\\n",
    "                       ,StructField(\"rating\", IntegerType(), True)])\n",
    "ratings = spark.createDataFrame(data,schema=schema)\n",
    "sc.setCheckpointDir('checkpoint/')\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALS_Classifier: \n",
    "    def __init__(self):\n",
    "        self.clf = ALS(rank=8, \n",
    "              maxIter=20, \n",
    "              regParam=0.06,\n",
    "              userCol=\"user\", \n",
    "              itemCol=\"item\", \n",
    "              ratingCol=\"rating\",\n",
    "              checkpointInterval=10, \n",
    "              seed=100,\n",
    "              intermediateStorageLevel=\"MEMORY_AND_DISK\", \n",
    "              finalStorageLevel=\"MEMORY_AND_DISK\")\n",
    "        self.evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "    def crossValidate(self, data):\n",
    "        schema = StructType([ StructField(\"user\", IntegerType(), True)\\\n",
    "                       ,StructField(\"item\", IntegerType(), True)\\\n",
    "                       ,StructField(\"rating\", IntegerType(), True)])\n",
    "        ratings = spark.createDataFrame(data, schema=schema)\n",
    "        self.model = self.clf.fit(ratings)\n",
    "    def predict(self, test):\n",
    "        schema = StructType([ StructField(\"user\", IntegerType(), True)\\\n",
    "                       ,StructField(\"item\", IntegerType(), True)\\\n",
    "                       ,StructField(\"rating\", IntegerType(), True)])\n",
    "        ratings = spark.createDataFrame(test,schema=schema)\n",
    "        p = self.model.transform(ratings).toPandas()\n",
    "        pred = p.rename(columns={'user': 'uid', 'item': 'iid', 'rating': 'r_ui', 'prediction': 'est'})\n",
    "        return pred\n",
    "    def crossValidate_normal(self, data):\n",
    "        \n",
    "        #pipeline = Pipeline(stages=[self.clf])\n",
    "\n",
    "        #paramGrid = ParamGridBuilder() \\\n",
    "        #    .addGrid(self.clf.regParam, [0.06]) \\\n",
    "        #    .addGrid(self.clf.rank, [8]) \\\n",
    "        #     .addGrid(self.clf.maxIter, [50]) \\\n",
    "        #     .build()\n",
    "        \n",
    "        #crossval = CrossValidator(estimator=pipeline,\n",
    "        #                  estimatorParamMaps=paramGrid,\n",
    "        #                  evaluator=self.evaluator,\n",
    "        #                  numFolds=5)\n",
    "        \n",
    "        #schema = StructType([ StructField(\"user\", IntegerType(), True)\\\n",
    "        #               ,StructField(\"item\", IntegerType(), True)\\\n",
    "        #               ,StructField(\"rating\", IntegerType(), True)])\n",
    "        #ratings = spark.createDataFrame(data, schema=schema)\n",
    "        self.model = self.clf.fit(data, seed=10)\n",
    "    def predict_normal(self, test):\n",
    "        p = self.model.transform(test)\n",
    "        return p\n",
    "    def rmse(self, predictions):\n",
    "        return self.evaluator.evaluate(predictions)\n",
    "    def predict_value(self, user, item):\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-e53f7676bc0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandomSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mals_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mALS_Classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mals_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrossValidate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-628736b79816>\u001b[0m in \u001b[0;36mcrossValidate_normal\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m#               ,StructField(\"rating\", IntegerType(), True)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m#ratings = spark.createDataFrame(data, schema=schema)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'seed'"
     ]
    }
   ],
   "source": [
    "(train, test) = ratings.randomSplit([0.8, 0.2])\n",
    "als_classifier = ALS_Classifier()\n",
    "als_classifier.crossValidate_normal(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-8f481c4f1342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mals_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mals_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 0.9921....65290783296\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-84ab3bdd6d0d>\u001b[0m in \u001b[0;36mrmse\u001b[0;34m(self, predictions)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-2.3.2-bin-hadoop2.7/python/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-2.3.2-bin-hadoop2.7/python/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \"\"\"\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-2.3.2-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/spark/spark-2.3.2-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-2.3.2-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "p = als_classifier.predict_normal(test)\n",
    "als_classifier.rmse(p) # 0.9921....65290783296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sub = p.toPandas()['prediction'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(user=1, item=84, rating=4)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ALSModel' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-93514d096485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mals_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-71-937f76e991ff>\u001b[0m in \u001b[0;36mpredict_value\u001b[0;34m(self, user, item)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ALSModel' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "als_classifier.predict_value(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "rank = 8\n",
    "numIterations = 30\n",
    "regParam = 0.06\n",
    "model = ALS.train(ratings, rank, numIterations, regParam, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+\n",
      "|user|item|rating|\n",
      "+----+----+------+\n",
      "|  44|   1|     4|\n",
      "|  61|   1|     3|\n",
      "|  67|   1|     4|\n",
      "|  72|   1|     3|\n",
      "|  86|   1|     5|\n",
      "|  90|   1|     4|\n",
      "| 108|   1|     3|\n",
      "| 114|   1|     3|\n",
      "| 120|   1|     2|\n",
      "| 135|   1|     5|\n",
      "| 152|   1|     4|\n",
      "| 165|   1|     3|\n",
      "| 182|   1|     3|\n",
      "| 310|   1|     3|\n",
      "| 318|   1|     1|\n",
      "| 333|   1|     3|\n",
      "| 355|   1|     2|\n",
      "| 390|   1|     4|\n",
      "| 401|   1|     4|\n",
      "| 410|   1|     2|\n",
      "+----+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, items = get_submission_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1176952, 2)\n"
     ]
    }
   ],
   "source": [
    "d = dict({'user': items, 'item': users })\n",
    "panda = pd.DataFrame.from_dict(d)\n",
    "print(panda.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176952"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType([ StructField(\"user\", IntegerType(), True)\\\n",
    "                       ,StructField(\"item\", IntegerType(), True)])\n",
    "final = spark.createDataFrame(panda, schema=schema)\n",
    "final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = model.predictAll(final.rdd.map(lambda x: (x[0], x[1])))\\\n",
    "    .map(lambda r: ((r[0], r[1]), r[2]))\\\n",
    "    .toDF()\\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176952, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176952, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post processing database\n",
    "pred_df['User'] = pred_df['_1'].apply(lambda x: x['_1'])\n",
    "pred_df['Movie'] = pred_df['_1'].apply(lambda x: x['_2'])\n",
    "pred_df['Rating'] = pred_df['_2']\n",
    "pred_df = pred_df.drop(['_1', '_2'], axis=1)\n",
    "pred_df = pred_df.sort_values(by=['Movie', 'User'])\n",
    "pred_df.index = range(len(pred_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1176947</th>\n",
       "      <td>9974</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.152257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176948</th>\n",
       "      <td>9977</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.455790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176949</th>\n",
       "      <td>9978</td>\n",
       "      <td>1000</td>\n",
       "      <td>2.893070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176950</th>\n",
       "      <td>9982</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.322231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176951</th>\n",
       "      <td>9996</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.768126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         User  Movie    Rating\n",
       "1176947  9974   1000  3.152257\n",
       "1176948  9977   1000  3.455790\n",
       "1176949  9978   1000  2.893070\n",
       "1176950  9982   1000  3.322231\n",
       "1176951  9996   1000  3.768126"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open(\"submission.csv\",\"w\")\n",
    "out.write('Id,Prediction\\n')\n",
    "for p in pred_df.iterrows():\n",
    "    rating = int(np.rint(p[1]['Rating']))\n",
    "    rating = 5 if rating == 6 else rating\n",
    "    rating = 1 if rating == 0 else rating\n",
    "    p_string = \"r{}_c{},{}\\n\".format(int(p[1]['User']), int(p[1]['Movie']), rating)\n",
    "    out.write(p_string)        \n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a30ceef0f7d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-b3c0d47312a9>\u001b[0m in \u001b[0;36mcreate_submission\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mp_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"r{}_c{},{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-2.3.2-bin-hadoop2.7/python/pyspark/mllib/recommendation.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, user, product)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mPredicts\u001b[0m \u001b[0mrating\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \"\"\"\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0.9.0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-2.3.2-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/spark/spark-2.3.2-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-2.3.2-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "create_submission(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline_Classifier: \n",
    "    def __init__(self):\n",
    "        self.clf = BaselineOnly()\n",
    "    def crossValidate(self, train):\n",
    "        reader = Reader(rating_scale=(1, 5))\n",
    "        train = Dataset.load_from_df(train, reader=reader)\n",
    "        train = train.build_full_trainset()\n",
    "        self.clf.fit(train)\n",
    "    def predict(self, test):\n",
    "        reader = Reader(rating_scale=(1, 5))\n",
    "        test = Dataset.load_from_df(test, reader=reader)\n",
    "        test = test.build_full_trainset().build_testset()\n",
    "        test_pred = self.clf.test(test)\n",
    "        return pd.DataFrame(test_pred)\n",
    "    def rmse(self, predictions):\n",
    "        return accuracy.rmse(predictions, verbose=True)\n",
    "baseline_classifier = Baseline_Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_Classifier: \n",
    "    def __init__(self):\n",
    "        self.clf = KNNBaseline(k=20, sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "    def crossValidate(self, train):\n",
    "        reader = Reader(rating_scale=(1, 5))\n",
    "        train = Dataset.load_from_df(train, reader=reader)\n",
    "        train = train.build_full_trainset()\n",
    "        self.clf.fit(train)\n",
    "    def predict(self, test):\n",
    "        reader = Reader(rating_scale=(1, 5))\n",
    "        test = Dataset.load_from_df(test, reader=reader)\n",
    "        test = test.build_full_trainset().build_testset()\n",
    "        test_pred = self.clf.test(test)\n",
    "        return pd.DataFrame(test_pred)\n",
    "    def rmse(self, predictions):\n",
    "        return accuracy.rmse(predictions, verbose=True)\n",
    "knn_classifier = KNN_Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlopeOne_Classifier: \n",
    "    def __init__(self):\n",
    "        self.clf = SlopeOne()\n",
    "    def crossValidate(self, train):\n",
    "        reader = Reader(rating_scale=(1, 5))\n",
    "        train = Dataset.load_from_df(train, reader=reader)\n",
    "        train = train.build_full_trainset()\n",
    "        self.clf.fit(train)\n",
    "    def predict(self, test):\n",
    "        reader = Reader(rating_scale=(1, 5))\n",
    "        test = Dataset.load_from_df(test, reader=reader)\n",
    "        test = test.build_full_trainset().build_testset()\n",
    "        test_pred = self.clf.test(test)\n",
    "        return pd.DataFrame(test_pred)\n",
    "    def rmse(self, predictions):\n",
    "        return accuracy.rmse(predictions, verbose=True)\n",
    "slope_classifier = SlopeOne_Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>user</th>\n",
       "      <th>est</th>\n",
       "      <th>est</th>\n",
       "      <th>est</th>\n",
       "      <th>r_ui</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>7375</td>\n",
       "      <td>3.538500</td>\n",
       "      <td>4.188634</td>\n",
       "      <td>3.908736</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>472</td>\n",
       "      <td>1494</td>\n",
       "      <td>4.038831</td>\n",
       "      <td>3.686864</td>\n",
       "      <td>3.895126</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>168</td>\n",
       "      <td>2568</td>\n",
       "      <td>4.297392</td>\n",
       "      <td>3.450430</td>\n",
       "      <td>4.656998</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>364</td>\n",
       "      <td>1308</td>\n",
       "      <td>4.381731</td>\n",
       "      <td>4.324887</td>\n",
       "      <td>4.124789</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>889</td>\n",
       "      <td>2782</td>\n",
       "      <td>3.896324</td>\n",
       "      <td>2.955418</td>\n",
       "      <td>3.874351</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item  user       est       est       est  r_ui\n",
       "0    27  7375  3.538500  4.188634  3.908736   5.0\n",
       "1   472  1494  4.038831  3.686864  3.895126   3.0\n",
       "2   168  2568  4.297392  3.450430  4.656998   3.0\n",
       "3   364  1308  4.381731  4.324887  4.124789   4.0\n",
       "4   889  2782  3.896324  2.955418  3.874351   3.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage_2_train.head()\n",
    "stage_2_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training model...\n",
      "Starting training model...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "(127111, 3)\n",
      "(127111, 3)\n",
      "(240561, 6)\n"
     ]
    }
   ],
   "source": [
    "def blend(models, data):\n",
    "    tmp, test = train_test_split(data, test_size=0.1)\n",
    "    train, val = train_test_split(tmp, test_size=0.12)\n",
    "    stage_2_train = pd.DataFrame()\n",
    "    stage_2_y = pd.DataFrame()\n",
    "    stage_2_test = pd.DataFrame()\n",
    "    stage_2_z = pd.DataFrame()\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        print(\"Starting training model...\")\n",
    "        model.crossValidate(train)\n",
    "        \n",
    "        val_pred = model.predict(val)\n",
    "        #print(val_pred)\n",
    "        val_pred = val_pred.sort_values(['uid','iid'],ascending=[True, True])\n",
    "        #val_pred = val_pred.rename(columns={'est': 'est' + str(i)})\n",
    "        stage_2_train = pd.concat([stage_2_train, val_pred['est']], axis=1)\n",
    "        stage_2_y = pd.concat([stage_2_y, val_pred['r_ui']], axis=1)\n",
    "        \n",
    "        test_pred = model.predict(test)\n",
    "        test_pred = test_pred.sort_values(['uid','iid'],ascending=[True, True])\n",
    "        #test_pred = test_pred.rename(columns={'est': 'est' + str(i)})\n",
    "        stage_2_test = pd.concat([stage_2_test, test_pred['est']], axis=1)\n",
    "        stage_2_z = pd.concat([stage_2_z, test_pred['r_ui']], axis=1)\n",
    "        \n",
    "    #print(np.sum(stage_2_y.iloc[:, 0] - stage_2_y.iloc[:, 1]))\n",
    "    \n",
    "    #print(np.sum(stage_2_z.iloc[:, 0] - stage_2_z.iloc[:, 1]))\n",
    "\n",
    "\n",
    "    stage_2_train['r_ui'] = stage_2_y.iloc[:,0]\n",
    "    stage_2_train = stage_2_train.sample(frac=1)\n",
    "    stage_2_test['r_ui'] = stage_2_z.iloc[:,0]\n",
    "    stage_2_test = stage_2_test.sample(frac=1)\n",
    "    \n",
    "    print(val.shape)\n",
    "    print(stage_2_train.shape)\n",
    "    print(pd.concat([val, stage_2_train], axis=1).shape)\n",
    "    \n",
    "    stage_2_train.reset_index(drop=True, inplace=True)\n",
    "    val.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    stage_2_test.reset_index(drop=True, inplace=True)\n",
    "    test.reset_index(drop=True, inplace=True)\n",
    "    return pd.concat([val[['item', 'user']], stage_2_train], axis=1), pd.concat([test[['item', 'user']], stage_2_test], axis=1)\n",
    " \n",
    "#blend([knn_classifier, baseline_classifier, als_classifier, slope_classifier], data)\n",
    "als_classifier = ALS_Classifier()\n",
    "\n",
    "stage_2_train, stage_2_test = blend([als_classifier, knn_classifier], data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9843103617228288"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Ridge()\n",
    "clf.fit(stage_2_train.drop(columns={'r_ui'}), stage_2_train['r_ui'])\n",
    "pred = clf.predict(stage_2_test.drop(columns={'r_ui'}))\n",
    "np.sqrt(mean_squared_error(pred, stage_2_test['r_ui']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user  item  rating\n",
      "961305   5661   768       4\n",
      "14745    9445     8       2\n",
      "902735   8336   705       3\n",
      "259053   8377   214       5\n",
      "1035924  2611   820       4\n",
      "Estimating biases using als...\n",
      "1.119333014551237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    \\ny_train = []\\nfor r in val_surprise.all_ratings():\\n    y_train.append(r[2])\\nclf = Ridge()\\nclf.fit(X_train, y_train)\\n\\ny_test = []\\nfor r in test_surprise.all_ratings():\\n    y_test.append(r[2])\\npred = clf.predict(X_test)\\n\\nprint(pred)\\n\\nnp.sqrt(mean_squared_error(pred, y_test))\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_and_predict(algo, train, val, test):\n",
    "    algo.fit(train)\n",
    "    val_pred = algo.test(val.build_testset())\n",
    "    test_pred = algo.test(test.build_testset())\n",
    "    return pd.Series(list(map(lambda x: x.est, val_pred))), pd.Series(list(map(lambda x: x.est, test_pred)))\n",
    "\n",
    "\n",
    "models = [#SVD(), \n",
    "          #KNNWithMeans(k=20, sim_options={'name': 'pearson_baseline', 'user_based': False}), \n",
    "          #SlopeOne(),\n",
    "          #NMF(),\n",
    "          #CoClustering(),\n",
    "          #BaselineOnly(),\n",
    "          baseline_classifier\n",
    "         ]\n",
    "tmp, test = train_test_split(data, test_size=0.1)\n",
    "print(tmp.head())\n",
    "train, val = train_test_split(tmp, test_size=0.12)\n",
    "X_train = pd.DataFrame()\n",
    "X_test = pd.DataFrame()\n",
    "for model in models:\n",
    "    model.crossValidate(train)\n",
    "    val_pred = model.predict(val)\n",
    "    test_pred = model.predict(test)\n",
    "    X_train = pd.concat([X_train, val_pred], axis=1)\n",
    "    X_test = pd.concat([X_test, test_pred], axis=1)\n",
    "    \n",
    "    clf = Ridge()\n",
    "    clf.fit(X_train, val['rating'])\n",
    "    pred = clf.predict(X_test)\n",
    "    print(np.sqrt(mean_squared_error(pred, test['rating'])))\n",
    "\n",
    "    \n",
    "\"\"\"    \n",
    "y_train = []\n",
    "for r in val_surprise.all_ratings():\n",
    "    y_train.append(r[2])\n",
    "clf = Ridge()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_test = []\n",
    "for r in test_surprise.all_ratings():\n",
    "    y_test.append(r[2])\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(pred)\n",
    "\n",
    "np.sqrt(mean_squared_error(pred, y_test))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
