{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import surprise\n",
    "import pandas as pd\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import KNNBaseline\n",
    "from surprise import Reader\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithZScore\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# Set the path & read and convert\n",
    "\n",
    "data_path = \"C:/Users/js360/Desktop/train_surprise.csv\"\n",
    "\n",
    "\n",
    "train = pd.read_csv(data_path, header=None)\n",
    "train = Dataset.load_from_df(train, reader=Reader())\n",
    "trainset = train.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALS-using Baseline grid searching\n",
    "param_dict = {'bsl_options':{'method' : ['als'] , \n",
    "              'n_epochs' : [20, 100],\n",
    "              'reg_u' : [10, 15, 20],\n",
    "              'reg_i' : [5, 10, 15],\n",
    "                            }\n",
    "          \n",
    "}\n",
    "\n",
    "gs = GridSearchCV(BaselineOnly, param_dict, cv=5)\n",
    "gs.fit(trainset)\n",
    "pd.DataFrame(gs.cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD-using Baseline grid searching\n",
    "param_dict = {'bsl_options':{'method' : ['sgd'] , \n",
    "              'n_epochs' : [20, 100],\n",
    "              'reg' : [0.01, 0.02, 0.1],\n",
    "              'learning_rate' : [0.005, 0.01, 0.1]\n",
    "                            }\n",
    "          \n",
    "}\n",
    "gs = GridSearchCV(BaselineOnly, param_dict, cv=5)\n",
    "gs.fit(trainset)\n",
    "pd.DataFrame(gs.cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNBaseline grid searching\n",
    "param_dict = {'bsl_options' : {'method' : ['als'], 'n_epochs' : [20]},\n",
    "              'sim_options':{'name' : ['msd', 'cosine', 'pearson', 'pearson_baseline'], 'min_support' : [1,5], 'shrinkage':[100],\n",
    "                            'k':[20,40,100]}\n",
    "\n",
    "}\n",
    "gs = GridSearchCV(KNNBaseline, param_dict, cv=5)\n",
    "gs.fit(trainset)\n",
    "pd.DataFrame(gs.cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best KNNBaseline, found by upper grid search\n",
    "algo_knn = KNNBaseline('bsl_options': {'method': 'als', 'n_epochs': 20},\n",
    "  'sim_options': {'name': 'pearson_baseline',\n",
    "   'min_support': 1,\n",
    "   'shrinkage': 100,\n",
    "   'k': 20,\n",
    "   'user_based': True})\n",
    "cross_validate(algo_knn, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SlopeOne CV\n",
    "from surprise import SlopeOne\n",
    "algo = SlopeOne()\n",
    "cross_validate(algo, train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoClustering CV\n",
    "from surprise import CoClustering\n",
    "algo = CoClustering()\n",
    "cross_validate(algo, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission code\n",
    "\n",
    "def create_submission(model):\n",
    "    out = open(\"submission.csv\",\"w\")\n",
    "    out.write('Id,Prediction\\n')\n",
    "    with open('C:/Users/js360/Desktop/submission_rows.csv') as samples:\n",
    "        for i, sample in enumerate(samples):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            tmp = sample.split('_')\n",
    "            row = int(tmp[0][1:].strip())\n",
    "            col = int(tmp[1][1:].strip())\n",
    "            p = model.predict(col, row, verbose=False)[-2]\n",
    "            p = max(min(np.rint(p),5),1)\n",
    "            p_string = \"r{}_c{},{}\\n\".format(row, col, p)\n",
    "            out.write(p_string)        \n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic algorithms created using Surprise AlgoBase Class\n",
    "\n",
    "class global_mean(AlgoBase):\n",
    "\n",
    "    def __init__(self, sim_options={}, bsl_options={}, verbose=False):\n",
    "\n",
    "        AlgoBase.__init__(self, sim_options=sim_options,\n",
    "                          bsl_options=bsl_options)\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, trainset):\n",
    "\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        return self\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "\n",
    "        return self.trainset.global_mean\n",
    "\n",
    "class user_mean(AlgoBase):\n",
    "\n",
    "    def __init__(self, sim_options={}, bsl_options={}, verbose=False):\n",
    "\n",
    "        AlgoBase.__init__(self, sim_options=sim_options,\n",
    "                          bsl_options=bsl_options)\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, trainset):\n",
    "\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        return self\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "\n",
    "        if not self.trainset.knows_user(u):\n",
    "            return self.trainset.global_mean\n",
    "        return np.mean([r for (i,r) in self.trainset.ur[u]])\n",
    "\n",
    "class item_mean(AlgoBase):\n",
    "\n",
    "    def __init__(self, sim_options={}, bsl_options={}, verbose=False):\n",
    "\n",
    "        AlgoBase.__init__(self, sim_options=sim_options,\n",
    "                          bsl_options=bsl_options)\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, trainset):\n",
    "\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        return self\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "\n",
    "        if not self.trainset.knows_item(i):\n",
    "            return self.trainset.global_mean\n",
    "        return np.mean([r for (u,r) in self.trainset.ir[i]])\n",
    "\n",
    "global_mean_algo = global_mean()\n",
    "user_mean_algo = user_mean()\n",
    "item_mean_algo = item_mean() \n",
    "baseline_algo = BaselineOnly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual testing of different SVDs\n",
    "\n",
    "data_path = \"C:/Users/js360/Desktop/train_surprise.csv\"\n",
    "train = pd.read_csv(data_path, header=None)\n",
    "train = Dataset.load_from_df(train, reader=Reader())\n",
    "trainset, testset = train_test_split(train)\n",
    "from surprise import accuracy\n",
    "i=0\n",
    "err= []\n",
    "for n_factors in  [5, 10, 20, 30, 40, 50, 75, 100]:\n",
    "    for n_epochs in [100]:\n",
    "        for lr_all in [0.01]:\n",
    "            for reg_all in [0.1]:\n",
    "                i += 1\n",
    "                print(i)\n",
    "                param = [n_factors, n_epochs, lr_all, reg_all]\n",
    "                a = SVD(n_epochs=n_epochs, n_factors=n_factors, lr_all=lr_all, reg_all=reg_all)\n",
    "                a.fit(trainset)\n",
    "                preds = a.test(testset)\n",
    "                err.append((param, accuracy.rmse(preds)))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD plot\n",
    "\n",
    "f = plt.figure(1)\n",
    "x = f.add_subplot(111)\n",
    "x.plot(nr_factors, results, linewidth=4, color='red')\n",
    "x.set_xlabel(\"n_factors\")\n",
    "x.set_ylabel(\"Test rmse\")\n",
    "x.set_xticks(nr_factors)\n",
    "x.grid()\n",
    "x.set_title(\"Test rmse by number of factors in SVD\")\n",
    "f.savefig(\"Svd_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best SVD, found by upper testing\n",
    "\n",
    "a = SVD(n_factors = 60, n_epochs = 100, lr_all = 0.01, reg_all = 0.1)\n",
    "cross_validate(a, train, cv=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
